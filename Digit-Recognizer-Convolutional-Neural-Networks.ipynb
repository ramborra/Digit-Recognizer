{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ram/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ram/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Generic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "#Importing Keras Libraries\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "#Importing sklearn Libraries\n",
    "from sklearn import grid_search\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# There are 10 digits : 0..9\n",
    "number_of_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (42000, 784))\n",
      "('Y_train original shape', (42000,))\n",
      "('Y_test original shape', (28000, 784))\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "Y_test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "#Printing shape of the data set\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"Y_train original shape\", Y_train.shape)\n",
    "print(\"Y_test original shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (42000, 28, 28, 1))\n",
      "('Y_test original shape', (28000, 28, 28, 1))\n"
     ]
    }
   ],
   "source": [
    "#Rescaling so that each pixel lies in the interval [0, 1] instead of [0, 255]\n",
    "X_train/=255.0\n",
    "Y_test/=255.0\n",
    "\n",
    "#Normalization and reshaping of input\n",
    "#As images are in grayscale, the number of channels is 1. For color images, it's be 3 (R, G, B).\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n",
    "Y_test  = Y_test.values.reshape(Y_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "Y_test  = Y_test.astype('float32')\n",
    "\n",
    "#After normalizing the shape of data\\n,\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"Y_test original shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, number_of_classes)\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=np.random.seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model ():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    BatchNormalization()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 751,370\n",
      "Trainable params: 751,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "295/295 [==============================] - 70s - loss: 1.4275 - acc: 0.4862 - val_loss: 0.2637 - val_acc: 0.9351\n",
      "Epoch 2/16\n",
      "295/295 [==============================] - 79s - loss: 0.5723 - acc: 0.8270 - val_loss: 0.0941 - val_acc: 0.9742\n",
      "Epoch 3/16\n",
      "295/295 [==============================] - 83s - loss: 0.3785 - acc: 0.8970 - val_loss: 0.0674 - val_acc: 0.9813\n",
      "Epoch 4/16\n",
      "295/295 [==============================] - 88s - loss: 0.3151 - acc: 0.9163 - val_loss: 0.0760 - val_acc: 0.9811\n",
      "Epoch 5/16\n",
      "295/295 [==============================] - 78s - loss: 0.2684 - acc: 0.9311 - val_loss: 0.0530 - val_acc: 0.9887\n",
      "Epoch 6/16\n",
      "295/295 [==============================] - 75s - loss: 0.2565 - acc: 0.9374 - val_loss: 0.0739 - val_acc: 0.9804\n",
      "Epoch 7/16\n",
      "295/295 [==============================] - 78s - loss: 0.2436 - acc: 0.9392 - val_loss: 0.0418 - val_acc: 0.9904\n",
      "Epoch 8/16\n",
      "295/295 [==============================] - 74s - loss: 0.2355 - acc: 0.9414 - val_loss: 0.0551 - val_acc: 0.9860\n",
      "Epoch 9/16\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9415\n",
      "Epoch 00008: reducing learning rate to 0.00010000000475.\n",
      "295/295 [==============================] - 76s - loss: 0.2386 - acc: 0.9415 - val_loss: 0.0881 - val_acc: 0.9750\n",
      "Epoch 10/16\n",
      "295/295 [==============================] - 72s - loss: 0.1828 - acc: 0.9539 - val_loss: 0.0389 - val_acc: 0.9912\n",
      "Epoch 11/16\n",
      "295/295 [==============================] - 73s - loss: 0.1735 - acc: 0.9549 - val_loss: 0.0385 - val_acc: 0.9921\n",
      "Epoch 12/16\n",
      "295/295 [==============================] - 73s - loss: 0.1648 - acc: 0.9590 - val_loss: 0.0356 - val_acc: 0.9914\n",
      "Epoch 13/16\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9582\n",
      "Epoch 00012: reducing learning rate to 1.0000000475e-05.\n",
      "295/295 [==============================] - 68s - loss: 0.1637 - acc: 0.9583 - val_loss: 0.0406 - val_acc: 0.9887\n",
      "Epoch 14/16\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9618\n",
      "Epoch 00013: reducing learning rate to 1.00000006569e-06.\n",
      "295/295 [==============================] - 75s - loss: 0.1538 - acc: 0.9618 - val_loss: 0.0333 - val_acc: 0.9912\n",
      "Epoch 15/16\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9582\n",
      "Epoch 00014: reducing learning rate to 1.00000011116e-07.\n",
      "295/295 [==============================] - 70s - loss: 0.1570 - acc: 0.9582 - val_loss: 0.0332 - val_acc: 0.9919\n",
      "Epoch 16/16\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9612\n",
      "Epoch 00015: reducing learning rate to 1.00000008274e-08.\n",
      "295/295 [==============================] - 68s - loss: 0.1545 - acc: 0.9612 - val_loss: 0.0396 - val_acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f8d8fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Augmentation : Creating batches of images and train on them.\n",
    "gen = ImageDataGenerator(featurewise_center=False, \n",
    "                         samplewise_center=False, \n",
    "                         featurewise_std_normalization=False, \n",
    "                         samplewise_std_normalization=False, \n",
    "                         zca_whitening=False, \n",
    "                         rotation_range=10, \n",
    "                         width_shift_range=0.10, \n",
    "                         height_shift_range=0.10, \n",
    "                         zoom_range=0.10,\n",
    "                         horizontal_flip=False,\n",
    "                         vertical_flip=False\n",
    "                        )\n",
    "gen.fit(X_train)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "test_gen.fit(X_val)\n",
    "\n",
    "annealer = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "\n",
    "#Creating model and fitting\n",
    "model = create_model()\n",
    "model.fit_generator(gen.flow(X_train, Y_train, batch_size=64), \n",
    "                    steps_per_epoch=X_train.shape[0]//batch_size, \n",
    "                    epochs=16,\n",
    "                    validation_data=test_gen.flow(X_val, Y_val, batch_size=64), \n",
    "                    validation_steps = 64, \n",
    "                    callbacks=[annealer]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4192/4200 [============================>.] - ETA: 0s('valid loss:', 0.037199317535269075)\n",
      "('valid accuracy:', 0.99047619047619051)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, Y_val, verbose=1)\n",
    "print('valid loss:', score[0])\n",
    "print('valid accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making Predictions and writing to a file\n",
    "results = model.predict(Y_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"dr_cnn_mnist_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time 1274 s.\n"
     ]
    }
   ],
   "source": [
    "end = dt.datetime.now()\n",
    "print('Total time {} s.'.format((end - start).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
