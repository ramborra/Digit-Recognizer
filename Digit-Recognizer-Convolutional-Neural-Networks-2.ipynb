{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ram/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ram/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Generic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "#Importing Keras Libraries\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "#Importing sklearn Libraries\n",
    "from sklearn import grid_search\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# There are 10 digits : 0..9\n",
    "number_of_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (42000, 784))\n",
      "('Y_train original shape', (42000,))\n",
      "('Y_test original shape', (28000, 784))\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "Y_test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "#Printing shape of the data set\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"Y_train original shape\", Y_train.shape)\n",
    "print(\"Y_test original shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (42000, 28, 28, 1))\n",
      "('Y_test original shape', (28000, 28, 28, 1))\n"
     ]
    }
   ],
   "source": [
    "#Rescaling so that each pixel lies in the interval [0, 1] instead of [0, 255]\n",
    "X_train/=255.0\n",
    "Y_test/=255.0\n",
    "\n",
    "#Normalization and reshaping of input\n",
    "#As images are in grayscale, the number of channels is 1. For color images, it's be 3 (R, G, B).\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n",
    "Y_test  = Y_test.values.reshape(Y_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "Y_test  = Y_test.astype('float32')\n",
    "\n",
    "#After normalizing the shape of data\\n,\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"Y_test original shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, number_of_classes)\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=np.random.seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model ():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    BatchNormalization()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 177,322\n",
      "Trainable params: 177,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "295/295 [==============================] - 67s - loss: 2.0103 - acc: 0.2507 - val_loss: 1.1112 - val_acc: 0.6199\n",
      "Epoch 2/32\n",
      "295/295 [==============================] - 65s - loss: 1.3085 - acc: 0.5276 - val_loss: 0.5697 - val_acc: 0.7967\n",
      "Epoch 3/32\n",
      "295/295 [==============================] - 65s - loss: 0.9076 - acc: 0.6963 - val_loss: 0.2952 - val_acc: 0.9249\n",
      "Epoch 4/32\n",
      "295/295 [==============================] - 65s - loss: 0.6964 - acc: 0.7843 - val_loss: 0.1658 - val_acc: 0.9556\n",
      "Epoch 5/32\n",
      "295/295 [==============================] - 65s - loss: 0.5564 - acc: 0.8371 - val_loss: 0.1443 - val_acc: 0.9585\n",
      "Epoch 6/32\n",
      "295/295 [==============================] - 65s - loss: 0.4884 - acc: 0.8587 - val_loss: 0.1138 - val_acc: 0.9691\n",
      "Epoch 7/32\n",
      "295/295 [==============================] - 65s - loss: 0.4076 - acc: 0.8836 - val_loss: 0.0632 - val_acc: 0.9818\n",
      "Epoch 8/32\n",
      "295/295 [==============================] - 65s - loss: 0.3840 - acc: 0.8938 - val_loss: 0.0792 - val_acc: 0.9786\n",
      "Epoch 9/32\n",
      "295/295 [==============================] - 65s - loss: 0.3483 - acc: 0.9042 - val_loss: 0.0631 - val_acc: 0.9813\n",
      "Epoch 10/32\n",
      "295/295 [==============================] - 66s - loss: 0.3426 - acc: 0.9065 - val_loss: 0.0583 - val_acc: 0.9845\n",
      "Epoch 11/32\n",
      "295/295 [==============================] - 65s - loss: 0.3079 - acc: 0.9159 - val_loss: 0.0791 - val_acc: 0.9808\n",
      "Epoch 12/32\n",
      "295/295 [==============================] - 65s - loss: 0.2922 - acc: 0.9239 - val_loss: 0.0539 - val_acc: 0.9855\n",
      "Epoch 13/32\n",
      "295/295 [==============================] - 65s - loss: 0.2844 - acc: 0.9269 - val_loss: 0.0750 - val_acc: 0.9835\n",
      "Epoch 14/32\n",
      "295/295 [==============================] - 65s - loss: 0.2761 - acc: 0.9284 - val_loss: 0.0412 - val_acc: 0.9894\n",
      "Epoch 15/32\n",
      "295/295 [==============================] - 65s - loss: 0.2672 - acc: 0.9320 - val_loss: 0.0650 - val_acc: 0.9848\n",
      "Epoch 16/32\n",
      "295/295 [==============================] - 65s - loss: 0.2658 - acc: 0.9343 - val_loss: 0.0713 - val_acc: 0.9826\n",
      "Epoch 17/32\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.9336\n",
      "Epoch 00016: reducing learning rate to 0.000500000023749.\n",
      "295/295 [==============================] - 65s - loss: 0.2597 - acc: 0.9338 - val_loss: 0.0516 - val_acc: 0.9875\n",
      "Epoch 18/32\n",
      "295/295 [==============================] - 66s - loss: 0.2211 - acc: 0.9448 - val_loss: 0.0430 - val_acc: 0.9877\n",
      "Epoch 19/32\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9487\n",
      "Epoch 00018: reducing learning rate to 0.000250000011874.\n",
      "295/295 [==============================] - 65s - loss: 0.2066 - acc: 0.9487 - val_loss: 0.0461 - val_acc: 0.9877\n",
      "Epoch 20/32\n",
      "295/295 [==============================] - 65s - loss: 0.1825 - acc: 0.9547 - val_loss: 0.0427 - val_acc: 0.9899\n",
      "Epoch 21/32\n",
      "295/295 [==============================] - 65s - loss: 0.1783 - acc: 0.9561 - val_loss: 0.0316 - val_acc: 0.9909\n",
      "Epoch 22/32\n",
      "295/295 [==============================] - 65s - loss: 0.1868 - acc: 0.9522 - val_loss: 0.0370 - val_acc: 0.9902\n",
      "Epoch 23/32\n",
      "295/295 [==============================] - 64s - loss: 0.1674 - acc: 0.9578 - val_loss: 0.0471 - val_acc: 0.9885\n",
      "Epoch 24/32\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9554\n",
      "Epoch 00023: reducing learning rate to 0.000125000005937.\n",
      "295/295 [==============================] - 64s - loss: 0.1855 - acc: 0.9553 - val_loss: 0.0347 - val_acc: 0.9899\n",
      "Epoch 25/32\n",
      "295/295 [==============================] - 65s - loss: 0.1760 - acc: 0.9574 - val_loss: 0.0383 - val_acc: 0.9909\n",
      "Epoch 26/32\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9579\n",
      "Epoch 00025: reducing learning rate to 6.25000029686e-05.\n",
      "295/295 [==============================] - 65s - loss: 0.1696 - acc: 0.9579 - val_loss: 0.0367 - val_acc: 0.9904\n",
      "Epoch 27/32\n",
      "295/295 [==============================] - 65s - loss: 0.1633 - acc: 0.9589 - val_loss: 0.0339 - val_acc: 0.9917\n",
      "Epoch 28/32\n",
      "295/295 [==============================] - 64s - loss: 0.1648 - acc: 0.9606 - val_loss: 0.0357 - val_acc: 0.9904\n",
      "Epoch 29/32\n",
      "295/295 [==============================] - 64s - loss: 0.1602 - acc: 0.9606 - val_loss: 0.0359 - val_acc: 0.9909\n",
      "Epoch 30/32\n",
      "295/295 [==============================] - 64s - loss: 0.1622 - acc: 0.9593 - val_loss: 0.0305 - val_acc: 0.9921\n",
      "Epoch 31/32\n",
      "295/295 [==============================] - 64s - loss: 0.1584 - acc: 0.9606 - val_loss: 0.0384 - val_acc: 0.9921\n",
      "Epoch 32/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 63s - loss: 0.1609 - acc: 0.9585 - val_loss: 0.0327 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121a4da50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Augmentation : Creating batches of images and train on them.\n",
    "gen = ImageDataGenerator(featurewise_center=False, \n",
    "                         samplewise_center=False, \n",
    "                         featurewise_std_normalization=False, \n",
    "                         samplewise_std_normalization=False, \n",
    "                         zca_whitening=False, \n",
    "                         rotation_range=20, \n",
    "                         width_shift_range=0.20, \n",
    "                         height_shift_range=0.20, \n",
    "                         zoom_range=0.10,\n",
    "                         horizontal_flip=False,\n",
    "                         vertical_flip=False\n",
    "                        )\n",
    "gen.fit(X_train)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "gen.fit(X_val)\n",
    "\n",
    "annealer = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=2, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "#Creating model and fitting\n",
    "model = create_model()\n",
    "model.fit_generator(gen.flow(X_train, Y_train, batch_size=64), \n",
    "                    steps_per_epoch=X_train.shape[0]//batch_size, \n",
    "                    epochs=32,\n",
    "                    validation_data=test_gen.flow(X_val, Y_val, batch_size=64), \n",
    "                    validation_steps = 64, \n",
    "                    callbacks=[annealer]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making Predictions and writing to a file\n",
    "results = model.predict(Y_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"dr_cnn_mnist_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
